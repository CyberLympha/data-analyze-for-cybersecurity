{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9274c80a",
   "metadata": {},
   "source": [
    "# Модели LSTM для прогнозирования временных рядов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831345c",
   "metadata": {},
   "source": [
    "**Цели работы:**\n",
    "\n",
    "0. Научиться подготавливать данные для LSTM. Разаработать метод скользящего окна для каждой модели.\n",
    "1. Разработать модель LSTM для\n",
    "    - одномерного \n",
    "    - многомерного \n",
    "    - многошагового прогнозирования временных рядов\n",
    "2. Для каждой модели дать оценку предсказанным значениям, используя метрики: \n",
    "    - Mean Squared Error\n",
    "    - Root Mean Squared Error\n",
    "    - Mean Absolute Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c605d",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27550c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, RepeatVector, TimeDistributed\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8514ef8",
   "metadata": {},
   "source": [
    "## Rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65057de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a8bc6",
   "metadata": {},
   "source": [
    "## Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24347f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e740a",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "...\n",
    "\n",
    "# demonstrate prediction\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0830c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1cdcb",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e811c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "...\n",
    "\n",
    "# demonstrate prediction\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e44cb",
   "metadata": {},
   "source": [
    "## Многомерные LSTM-модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe0f40",
   "metadata": {},
   "source": [
    "#### Ряд с несколькими входами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d6184",
   "metadata": {},
   "source": [
    "Мы можем преобразовать эти три массива данных в единый набор данных, где каждая строка — это временной шаг, а каждый столбец — это отдельный временной ряд. Это стандартный способ хранения параллельных временных рядов в файле CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "\n",
    "out_seq = array([in_seq1[i] + i*np.sin(in_seq2[i]) for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print('X.shape, y.shape = ', X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543b0e4",
   "metadata": {},
   "source": [
    "Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f0dc2",
   "metadata": {},
   "source": [
    "Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14478af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5cba22",
   "metadata": {},
   "source": [
    "#### Несколько параллельных временных рядов\n",
    "Задача альтернативных временных рядов возникает, когда имеется несколько параллельных временных рядов и для каждого из них необходимо спрогнозировать значение.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print('X.shape, y.shape = ', X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd3a7e",
   "metadata": {},
   "source": [
    "Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=400, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e01d0a",
   "metadata": {},
   "source": [
    "### Многошаговые модели LSTM\n",
    "Задача прогнозирования временных рядов, требующая прогнозирования нескольких временных шагов в будущем, может называться многошаговым прогнозированием временных рядов.\n",
    "\n",
    "В частности, это задачи, в которых горизонт или интервал прогнозирования превышает один временной шаг.\n",
    "\n",
    "Существует два основных типа моделей LSTM, которые можно использовать для многошагового прогнозирования:\n",
    "\n",
    "1. Модель векторного вывода\n",
    "2. Модель кодера-декодера\n",
    "Прежде чем рассмотреть эти модели, давайте сначала рассмотрим подготовку данных для многошагового прогнозирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a8826",
   "metadata": {},
   "source": [
    "#### Модель векторного вывода\n",
    "Как и другие типы моделей нейронных сетей, LSTM может напрямую выводить вектор, который можно интерпретировать как многошаговый прогноз.\n",
    "\n",
    "Этот подход рассматривался в предыдущем разделе, где один временной шаг каждого выходного временного ряда прогнозировался как вектор.\n",
    "\n",
    "Как и в случае с LSTM для одномерных данных в предыдущем разделе, подготовленные образцы должны быть сначала переформированы. LSTM ожидает, что данные будут иметь трехмерную структуру [ выборки, временные шаги, признаки ], а в этом случае у нас есть только один признак, поэтому переформирование будет простым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f42371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=50, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([100, 110, 120])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902ccb7",
   "metadata": {},
   "source": [
    "#### Модель кодера-декодера\n",
    "Модель, специально разработанная для прогнозирования выходных последовательностей переменной длины, называется LSTM-кодировщик-декодер .\n",
    "\n",
    "Модель была разработана для задач прогнозирования, в которых имеются как входные, так и выходные последовательности, так называемые задачи «последовательность-к-последовательности» или seq2seq, например, при переводе текста с одного языка на другой.\n",
    "\n",
    "Эту модель можно использовать для многошагового прогнозирования временных рядов.\n",
    "\n",
    "Как следует из названия, модель состоит из двух подмоделей: кодера и декодера.\n",
    "\n",
    "**Кодер** — это модель, отвечающая за чтение и интерпретацию входной последовательности. Выходные данные кодера — это вектор фиксированной длины, который представляет собой интерпретацию последовательности моделью. Кодер традиционно представляет собой модель Vanilla LSTM, хотя могут использоваться и другие модели кодеров, такие как Stacked, Bidirectional и CNN.\n",
    "\n",
    "**Декодер** использует выходной сигнал кодера в качестве входного сигнала.\n",
    "\n",
    "Сначала выходной сигнал кодера фиксированной длины повторяется один раз для каждого требуемого временного шага в выходной последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f5b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Кодер\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "\n",
    "# Декодер\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "\n",
    "\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994a173",
   "metadata": {},
   "source": [
    "## Многомерные многошаговые модели LSTM\n",
    "В предыдущих разделах мы рассмотрели одномерное, многомерное и многошаговое прогнозирование временных рядов.\n",
    "\n",
    "Можно смешивать и сопоставлять различные типы моделей LSTM, представленные до сих пор для различных проблем. Это также применимо к проблемам прогнозирования временных рядов, которые включают многомерное и многошаговое прогнозирование, но это может быть немного сложнее.\n",
    "\n",
    "В этом разделе мы приведем краткие примеры подготовки данных и моделирования для многомерного многошагового прогнозирования временных рядов в качестве шаблона для облегчения этой задачи, а именно:\n",
    "\n",
    "1. Многоканальный вход, многошаговый выход.\n",
    "2. Множественный параллельный вход и многошаговый выход.\n",
    "\n",
    "Пожалуй, самым большим камнем преткновения является подготовка данных, поэтому именно на ней мы сосредоточим свое внимание."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0be00",
   "metadata": {},
   "source": [
    "### Многоступенчатый выход с несколькими входами\n",
    "\n",
    "Существуют такие задачи прогнозирования многомерных временных рядов, когда выходной ряд отделен, но зависит от входного временного ряда, и для выходного ряда требуется несколько временных шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b20681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out-1\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9311c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(\"X.shape, y.shape = \", X.shape, y.shape)\n",
    "    \n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae12cd",
   "metadata": {},
   "source": [
    "Векторный выход Stacked LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1244a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100649e",
   "metadata": {},
   "source": [
    "### Множественный параллельный вход и многошаговый выход\n",
    "Проблема с параллельными временными рядами может потребовать прогнозирования нескольких временных шагов каждого временного ряда.\n",
    "\n",
    "Мы можем использовать последние три временных шага из каждого из трех временных рядов в качестве входных данных для модели и прогнозировать следующие временные шаги каждого из трех временных рядов в качестве выходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(\"X.shape, y.shape = \", X.shape, y.shape)\n",
    "\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b223e0a",
   "metadata": {},
   "source": [
    "Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=300, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af041e97",
   "metadata": {},
   "source": [
    "**Реализуйте модель \"Векторного вывода\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da12a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48c55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743567e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
